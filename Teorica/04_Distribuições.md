# DistribuiÃ§Ãµes

As **fmp** e **fdp** (no caso contÃ­nuo), podem assumir as mais **variadas formas**

DistribuiÃ§Ãµes mais comuns:

- **Discretas**
  - [*Bernoulli*](#bernoulli)
  - [*Binomial*](#binomial)
  - [*Poisson*](#poisson)
  - [*GeomÃ©trica*](#geomÃ©trica) 

- **ContÃ­nuas**
  - [*Uniforme*](#uniforme)
  - [*Normal*](#normal)
  - [*Exponencial*](#exponencial)
 
## Bernoulli

Diretamente relacionada com as **experiÃªncias de Bernoulli**

Seja **A** um acontecimento relacionado com o **resultado** de uma **experiÃªncia aleatÃ³ria**

A **variÃ¡vel de Bernoulli** define-se como

**I**_A(w) = w ğœ– A ? 1 : 0	

### Exemplo
S_i = {0,1}
p = Pr(A)

p_i(1) = p
p_i(0) = 1-p

E[I] = 1 * p + 0 * (1-p) = p -> E^2[I] = p^2

var(I) = **E[I^2] - E^2[I]** = (1^2 * p) - p^2 = p^2 - p = **p * (1-p)**

## Binomial

Diretamente relacionada com a **Lei Binomial**

Seja **X** o **nÃºmero de vezes** que um acontecimento **A** ocorre em **n** experiÃªncias de Bernoulli
- X representa o nÃºmero de **sucessos em n** experiÃªncias

**X = SUM_j=1 to n (I_j)**

**p_x(k)** = Pr(X=k) = **(n over k) * p^k * (1-p)^(n-k)**

F_x(x) = SUM_k=0 to x (p_x(k))

### MÃ©dia e VariÃ¢ncia

FÃ¡cil derivar, temos **n variÃ¡veis de Bernoulli** independentes, designadas por **I_i**

- **E[X]** = E[SUM I_i] = SUM E[I_i] = p + p + p + p + ... = **n * p**

- **var(X)** = var(SUM I_i) = SUM var(I_i) = ... = **n * p * (1-p)**

### Exemplo

Num conjunto de programas a **probabilidade** de haver **pelo menos um erro** ao analisar um **conjunto de 1000 linhas** de cÃ³digo Ã© **p**

Se o total de linhas for **N * 1000** e dividirmos em **blocos de 1000** linhas, a probabilidade de **k** blocos terem erros Ã© dada pela **distribuiÃ§Ã£o Binomial**

Se em **1000** linhas a probabilidade Ã© **p**, em **100** a probabilidade serÃ¡ de **p / 10**

Assumimos entÃ£o:
- blocos de **100** linhas --> **limite so sumatÃ³rio**
- **1000** blocos --> **n = 1000**
- p = 0.098

Assim:
- **p_x(k)** = Pr(X=k) = **(n over k) * p^k * (1-p)^(n-k)**

passa a:

- **P = F_x(100) = SUM_k=0 to 100 ( (10000 over k) * 0.098^k * (0.902)^(1000-k) )**

## GeomÃ©trica

Seja **X** o **nÃºmero de vezes** que Ã© necessÃ¡rio **repetir** uma **experiÃªncia de Bernoulli** atÃ© obter um **sucesso**

- p_x(k) = **p**(1-p)^(k-1)

*Porque teremos k-1 insucessos e de pois sucesso* 


### MÃ©dia e VariÃ¢ncia

- **E[X] = 1 / p**
  - SUM_i=1 to inf (i * p(1-p)^(i-1))

- **var(X) = (1-p)/(p^2)**


## Poisson

Foca-se apenas no nÃºmero de ocorrÃªncias (discreto) num intervalo de contÃ­nuo

Esta distribuiÃ§Ã£o **nÃ£o tem nÃºmero de experiÃªncias (n)** com na Binomial
  - As ocorrÃªncias sÃ£o independentes entre si

Problemas de distribuiÃ§Ã£o Binomial em que **n Ã© grande** e o **p Ã© pequeno**, ou seja, **eventos raros**, sÃ£o bons candidatos Ã¡ distribuiÃ§Ã£o de Poisson
  - Se **n > 20** e **n * p <= 7** --> **Poisson**

Considerando uma variÃ¡vel binomial, **n cresce e p decresce** de forma a **n * p --> ğœ†**

- **p ~= ğœ† / n** logo **1 - p ~= 1 - ğœ† / n**

- **p_x(k) = (ğœ†^k / k!) * e^(-ğœ†)**

### MÃ©dia e VariÃ¢ncia

- **E[X] = ğœ†**

- **var(X) = ğœ†**

### Binomial --> Poisson

1. Calcular **mÃ©dia** da Binomial **Âµ = n * p**

2. Como Âµ Ã© o **valor esperado (E[X])** da Binomial, transforma-se em **ğœ†** de Poisson

3. Usar fÃ³rmula de Poisson
  - **p_x(k) = (ğœ†^k / k!) * e^(-ğœ†)**
  

### Exemplo

Clientes entram no banco a uma mÃ©dia de **3.2** a cada **4 minutos** durante um dia da semana. Qual a probabilidade de  haver **mais de 7** clientes num intervalo de **4 minutos** durante um dia Ã¡ tarde

Resolvendo:

**X** = nÃºmero de clientes

Prentendemos **P("X > 7 clientes / 4 minutos")**

**ğœ† = 3.2**

A soluÃ§Ã£o requer que que calculemos a probabilidade para todos os **k > 7**. Ou entÃ£o calculamos o **complemento da probabilidade** de **k <= 7**

Resulta que: SUM_k=0 to 7 ( 3.2^k / k! ) * e^(-3.2) = **0.0168**

*k --> valores possÃ­vies para X*

## Uniforme

- **F_X(x) = x > b ? 1 : (x >= a ? (x-a)/(b-a) : 0 )**

- **E[X] = (a + b) / 2**

- **var(X) = ( b -2 )^2 / 12**

### rand() em Matlab

FunÃ§Ã£o gera nÃºmeros em **distribuiÃ§Ã£o uniforme** com *a = 0* e *b = 1*

Para obter **U(a,b)**:
- a + rand() * (b - a)

## Normal
*ou Gaussiana*

Uma variÃ¡vel aleatÃ³ria diz-se **normal** (ou gaussiana) se:
- **f_X(x) = 1 / (sqr(2 * ğœ‹) * ğœ)**

Podemos usat a notaÃ§Ã£o **N(m, ğœ^2)**
- **m** --> **mÃ©dia**
- **ğœ** --> **desvio padrÃ£o**

**FunÃ§Ã£o de distribuiÃ§Ã£o acumulada**
- F_X(x) = (1 / (sqr(2 * ğœ‹) * ğœ)) * Integral_-inf to +inf ( e^(- (t-m)^2 / (2 * ğœ^2) ) dt )

- **E[X] = m** (por vezes Ã© usado **Î¼** para representar a mÃ©dia)
- **var(X) = ğœ^2**

### Gaussiana normalizada

Com infinitas combinaÃ§Ãµes de **m** e **ğœ** podem gerar-se infinitas curvas

A **Gaussiana normalizada (N(0,1))** permite transforma-las em uma sÃ³ curva

A fÃ³rmula de conversÃ£o Ã©:
- Z = (x - m) / ğœ

*Ou seja, subtrair a mÃ©dia e dividir pelo desvio padrÃ£o*

**FunÃ§Ã£o densidade de probabilidade**:
- **ğœ™(ğ‘¥) = ( 1 / sqr(2 * ğœ‹)) * e^(-x^2 / 2)**

**FunÃ§Ã£o de distribuiÃ§Ã£o acumulada**:
- **Î¦(x) = (1 / sqr(2 * ğœ‹)) * Integral_-inf to x (e^(t^2 / -2) dt)**

**FunÃ§Ã£o distribuiÃ§Ã£o acumulada**:

**N(m,ğœ^2)** tambÃ©m pode ser expressa em termo de **Î¦(x)**
- **F_X(x) = Î¦((x - m) / ğœ)**

### DistribuiÃ§Ã£o Normal e a Binomial

FunÃ§Ã£o **massa de probabilidade** da Binomial, com **m = n * p** e **ğœ^2 = n * p * (1-p)**, em que **m seja muito pequeno e n elevado**, pode aproximar-se por:
- **(1 / sqr(2 * ğœ‹) * ğœ) * e^(-(k - m)^2/(2 * ğœ^2))**

Ou seja a **distribuiÃ§Ã£o normal**
- *Com m = n * p e variÃ¢ncia = n * p * (1-p)**

## Exponencial

Ã‰ **nÃ£o negativa**

Relacionada com a distribuiÃ§Ã£o de **Poisson**

- **f_X(x) = x >= 0 ? (ğœ† * e^(-ğœ† * x)) : 0**

- **F_X(x) = x >= 0 ? (1 - e^(-ğœ† * x)) : 0**

- **E[X] = 1 / ğœ†**

- **var(X) = 1 / ğœ†^2**

### Exemplo

A vida Ãºtil, em milhares de horas, de um componente de um robÃ´ Ã© uma variÃ¡vel aleatÃ³ria com distribuiÃ§Ã£o exponencial de valor mÃ©dio 10 (milhares de horas)

Qual a probabilidade de um desses componentesselecionado ao acaso durar menos de 4000 horas?

Resolvendo:

**ğœ†** = 1 / 10 = **0.1**

**P[X < 4]** = Integral_0 to 4 ( 0.1 * e^(-0.1 * x) dx) = F_X(4) = **0.33**
