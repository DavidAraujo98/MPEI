# SituaÃ§Ãµes Limite

Como saber o que acontece quando **n tende para infinito** ao valor esperado e variÃ¢ncia da MÃ©dia e *n* mediÃ§Ãµes

## Index

- [Desigualdades de Markov e Chebyshev](#markov-e-chebyshev)
- [Lei dos Grandes NÃºmeros](#lei-dos-grandes-nÃºmeros)
- [Teorema do Limite Central](#teorema-do-limite-central)

## Markov e Chebyshev

Permitem estabelecer **facilmente majorantes** para probabilidades de certas classes de acontecimentos
- partindo apenas do conhecimento da **mÃ©dia** e **variÃ¢ncia** de uma variÃ¡vel aleatÃ³ria

### Desigualdade de Markov

X Ã© uma v.a. **nÃ£o negativa**

- **P(X >= a) <= E[X] / a , âˆ€a > 0**

Esta desigualdade dÃ¡ um **limite superior** para a probabilidade de a funÃ§Ã£o *X* ser maior ou igual a um determinado valor

**DemonstraÃ§Ã£o**

E[X] = ?

= ~~Integral_0 to a (x * f_x(x)) dx~~ + Integral_a to +inf (x * f_x(x)) dx >= 

=> Integral_a to +inf (x * f_x(x)) dx >= Integral_a to +inf (a * f_x(x)) dx >= a * P[X >= a]

Logo: **P[X >= a] <= E[X] / a**

#### Exemplo

MÃ©dia de alturas: 1,65m

Qual o **limite superior** de probabilidade de um indivÃ­duo ultrapassar os 2 metros

- P(X >= 2) <= 1,65 / 2 = 0,825

### Desigualdade de Chebyshev

- **P(|X - E[X]| >= a) <= Var(X) / a^2**

Ou em alternativa

- **P(|X - E[X]| < a) >= 1 - Var(X) / a^2**

Se **expressarmos a em funÃ§Ã£o do desvio padrÃ£o**, fazendo **a = hğœ**, teremos:
- P(|X - E[X]| >= hğœ) <= ğœ^2 / (hğœ)^2 = 1 / h^2

Qual a **probabilidade da mÃ©dia das amostras se aproximar do valor mÃ©dio** (a menos de ğœ–) ?
- P(|Mn âˆ’ E[Mn]| < ğœ–)

Usando Chebyshev temos:

P(|Mn - E[Mn]| >= ğœ–) <= Var(Mn) / ğœ–^2

= P(|Mn - E[Mn]| >= ğœ–) <= (ğœ^2 / n) / ğœ–^2

= P(|Mn - E[Mn]| < ğœ–) >= 1 - ğœ^2 / (ğœ–^2 * n)

passando ao **limite**

lim_n->inf P(|Mn - E[Mn]| < ğœ–) = 1

Chamado de **Lei Fraca dos Grandes NÃºmeros**

## Lei dos Grandes NÃºmeros

**Lei Fraca dos Grandes NÃºmeros**: para um valor de *n* suficientemente elevado a mÃ©dia das amostras estarÃ¡ muito prÃ³xima do valor esperado

**Lei forte**: garante que Ã© certo que o limite para que tende a mÃ©dia (das amostras) Ã© o valor esperado

### DefiniÃ§Ã£o frequencista

Seja *Ij* uma variÃ¡vel aleatÃ³ria indicadora da ocorrÃªncia do evento A na experiÃªncia de ordem *j*
- [1 significa que A ocorreu]

O nÃºmero total de ocorrÃªncias de *A* nas *n* experiÃªncias serÃ¡:
- **Nn= I1 + I2 + ... + In**

**FrequÃªncia relativa** de *A*
- f_A(n) = (I1 + ... + In) / n

f_A Ã© a mÃ©dia das amostras das variÃ¡veis aleatÃ³rias *Ii*

EntÃ£o
- lim_n->inf P(|f_A(n) - p(A)| < ğœ–) = 1

e

- P[lim_n->inf f_A(n) = p(A)] = 1

Permite dizer que a **frequÃªncia relativa Ã© uma boa estimativa da probabilidade**

## Teorema do Limite Central

Teorema: **demonstra-se que a soma de variÃ¡veis i.i.d. tende para uma distribuiÃ§Ã£o normal quando o nÃºmero de variÃ¡veis Ã© grande**

Ã‰ a razÃ£o da **importÃ¢ncia da distribuiÃ§Ã£o Normal**

### Aplicando Ã  mÃ©dia Mn

Mn = (1/n) * SUM_i=1 to n (Xi)

Pelo TLC:
- Mn ~ N(ğœ‡,ğœ2/ğ‘›) quando n -> +inf

A distribuiÃ§Ã£o da mÃ©dia de n variÃ¡veis i.i.d. **tende** para uma **distribuiÃ§Ã£o normal** com parÃ¢metros *ğœ‡* e *ğœ2/ğ‘›*